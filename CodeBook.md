The data set generated by the `run_analysis.R` script is a transformed version of the Human Activity Recognition Using Smartphones Data Set of the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones) as the Getting and Cleaning Data Coursera course project.

The original data set contained 561 measurement variables, out of those 66 are picked. These are the means and standard deviations of the various signals.

Quoting the original description of the data set (from `features_info.txt`, supplied with the original data set):

"The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

Finally a Fast Fourier Transform (FFT) was applied to some of these signals producing fBodyAcc-XYZ, fBodyAccJerk-XYZ, fBodyGyro-XYZ, fBodyAccJerkMag, fBodyGyroMag, fBodyGyroJerkMag. (Note the 'f' to indicate frequency domain signals). 

These signals were used to estimate variables of the feature vector for each pattern:
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

* tBodyAcc-XYZ
* tGravityAcc-XYZ
* tBodyAccJerk-XYZ
* tBodyGyro-XYZ
* tBodyGyroJerk-XYZ
* tBodyAccMag
* tGravityAccMag
* tBodyAccJerkMag
* tBodyGyroMag
* tBodyGyroJerkMag
* fBodyAcc-XYZ
* fBodyAccJerk-XYZ
* fBodyGyro-XYZ
* fBodyAccMag
* fBodyAccJerkMag
* fBodyGyroMag
* fBodyGyroJerkMag
"

These are 33 signals (-XYZ ones are 3 separate signals for the 3 axes), for each one there are 2 variables, one for the mean (suffixed with -mean() and one for the standard deviation, suffixed with -std(), for 3-axial signals, the -X/-Y/-Z suffix comes after that in the label of the variable), summing up to the 66 variables, each represented by a column of the table and labeled accordingly. These original measurement variable names are used, which come from `features.txt`, also supplied with the original data set.

The data set contains measurements of these signals for different subjects and an outcome of the activity identified.

There are 6 different activity types: 1) WALKING, 2) WALKING_UPSTAIRS, 3) WALKING_DOWNSTAIRS, 4) SITTING, 5) STANDING, 6) LAYING, outcomes are represented by these activity labels, which as well come from the original data set (`activity_labels.txt`).

The data set transformation provides two data sets, a final one and one optional intermediary data set. The intermediary contains all the different measurements, one per row, the subject and the identified activity being additional 2 variables (as 'subject' and 'activity'). The final data set aggregates the measurements, for each subject-activity pair it provides a single row containing the averages of the measurement variables. There are 30 subjects and 6 activity types, therefore there are 30x6=180 rows. The final data set does not contain the 'subject' and 'activity' variables, instead the rows are named as '< activity label >.< subject >'.
